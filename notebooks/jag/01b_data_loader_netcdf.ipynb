{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Modules and File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/ipykernel_launcher.py:9: MatplotlibDeprecationWarning: \n",
      "The text.latex.unicode rcparam was deprecated in Matplotlib 3.0 and will be removed in 3.2.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os.path import abspath\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib\n",
    "matplotlib.rcParams['text.latex.unicode']=False\n",
    "import datetime\n",
    "from operator import add\n",
    "import pickle\n",
    "from sklearn.impute import SimpleImputer as Imputer\n",
    "from osgeo import gdal\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import richdem as rd\n",
    "import joblib\n",
    "filename = 'finalized_model.sav'\n",
    "\n",
    "\n",
    "imp = Imputer(strategy='mean')\n",
    "\n",
    "# --------------------- #\n",
    "# Lets Rips Some Treads #\n",
    "# --------------------- #\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "\n",
    "if abspath('../../utils/') not in sys.path:\n",
    "    sys.path.append(abspath('../../utils/'))\n",
    "from utils import GetExtent, ventana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SITENAME = 'tuolumne'\n",
    "name = 'snowdepth'\n",
    "formato = 'netcdf'\n",
    "YEAR = '2015'\n",
    "path_to_data = f'/srv/shared/deep_stac/data/{name}/{formato}/{YEAR}'\n",
    "path_to_topo = '/srv/shared/deep_stac/data/topo.nc'\n",
    "files = os.listdir(path_to_data)\n",
    "files = np.sort([f for f in files if 'int' in f])\n",
    "fname_list = [os.path.join(path_to_data, f) for f in np.sort(files)]\n",
    "dates = [d.split('_')[0] for d in files]\n",
    "dates = np.sort(dates).tolist()\n",
    "# dates = [pd.to_datetime(d.split('_')[0]).date() for d in files]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Lidar and Topo Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/xarray/backends/api.py:783: FutureWarning: In xarray version 0.13 `auto_combine` will be deprecated.\n",
      "  coords=coords)\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/xarray/backends/api.py:783: FutureWarning: Also `open_mfdataset` will no longer accept a `concat_dim` argument.\n",
      "To get equivalent behaviour from now on please use the new\n",
      "`combine_nested` function instead (or the `combine='nested'` option to\n",
      "`open_mfdataset`).The datasets supplied do not have global dimension coordinates. In\n",
      "future, to continue concatenating without supplying dimension\n",
      "coordinates, please use the new `combine_nested` function (or the\n",
      "`combine='nested'` option to open_mfdataset.\n",
      "  coords=coords)\n"
     ]
    }
   ],
   "source": [
    "# --------------- #\n",
    "# Read Lidar Data #\n",
    "# --------------- #\n",
    "ds = xr.open_mfdataset(fname_list, concat_dim='flight_date', chunks={'x':1000, 'y':1000})\n",
    "ds.close()\n",
    "\n",
    "dtopo = xr.open_dataset(path_to_topo, chunks={'x':1000, 'y':1000})\n",
    "dtopo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sub select features to include to the dem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_to_lidar = ['dem','veg_height','mask']\n",
    "dtopo = dtopo[add_to_lidar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- #\n",
    "# Remove This features #\n",
    "# -------------------- #\n",
    "\n",
    "ds = ds.drop('transverse_mercator')\n",
    "\n",
    "dtopo = dtopo.expand_dims('flight_date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Data Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOPO: \n",
      "\n",
      " <xarray.Dataset>\n",
      "Dimensions:     (flight_date: 1, x: 17569, y: 17002)\n",
      "Coordinates:\n",
      "  * x           (x) float32 254007.0 254010.0 254013.0 ... 306708.0 306711.0\n",
      "  * y           (y) float32 4230327.0 4230324.0 ... 4179327.0 4179324.0\n",
      "Dimensions without coordinates: flight_date\n",
      "Data variables:\n",
      "    dem         (flight_date, y, x) float32 dask.array<shape=(1, 17002, 17569), chunksize=(1, 1000, 1000)>\n",
      "    veg_height  (flight_date, y, x) float32 dask.array<shape=(1, 17002, 17569), chunksize=(1, 1000, 1000)>\n",
      "    mask        (flight_date, y, x) uint8 dask.array<shape=(1, 17002, 17569), chunksize=(1, 1000, 1000)>\n",
      "Attributes:\n",
      "    last_modified:       [2019-08-08 17:17:16] Data added or updated\n",
      "    Conventions:         CF-1.6\n",
      "    dateCreated:         2019-08-08 17:17:34\n",
      "    Title:               Topographic Images for SMRF/AWSM\n",
      "    history:             [2019-08-08 17:17:34] Create netCDF4 file using Basi...\n",
      "    institution:         USDA Agricultural Research Service, Northwest Waters...\n",
      "    generation_command:  /usr/local/bin/basin_setup -f corrected_tuolumne_sub... \n",
      "\n",
      "\n",
      "Lidar:\n",
      "\n",
      " <xarray.Dataset>\n",
      "Dimensions:  (flight_date: 10, x: 17569, y: 17002)\n",
      "Coordinates:\n",
      "  * x        (x) float64 2.54e+05 2.54e+05 2.54e+05 ... 3.067e+05 3.067e+05\n",
      "  * y        (y) float64 4.179e+06 4.179e+06 4.179e+06 ... 4.23e+06 4.23e+06\n",
      "Dimensions without coordinates: flight_date\n",
      "Data variables:\n",
      "    Band1    (flight_date, y, x) float32 dask.array<shape=(10, 17002, 17569), chunksize=(1, 1000, 1000)>\n",
      "Attributes:\n",
      "    GDAL_AREA_OR_POINT:  Area\n",
      "    Conventions:         CF-1.5\n",
      "    GDAL:                GDAL 2.4.1, released 2019/03/15\n",
      "    history:             Wed Sep 11 15:42:33 2019: GDAL CreateCopy( /srv/shar...\n"
     ]
    }
   ],
   "source": [
    "print('TOPO: \\n\\n',dtopo, '\\n\\n\\nLidar:\\n\\n', ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['date'] = (['date'], dates)\n",
    "ds = ds.assign_coords(date=ds.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20150218',\n",
       " '20150306',\n",
       " '20150325',\n",
       " '20150403',\n",
       " '20150409',\n",
       " '20150415',\n",
       " '20150427',\n",
       " '20150501',\n",
       " '20150528',\n",
       " '20150608']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos['snowdepth'] = np.divide(ds.Band1[0,:,:].values,100)\n",
    "datos['vegh'] = dtopo.veg_height.values.squeeze(axis=0)\n",
    "datos['dem'] = dtopo.dem.values.squeeze(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(17002, 17569)\n"
     ]
    }
   ],
   "source": [
    "print(type(datos['dem']))\n",
    "print(datos['dem'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Topographic Features from DEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning! No geotransform defined. Choosing a standard one! (Top left cell's top let corner at <0,0>; cells are 1x1.)\n",
      "Warning! No geotransform defined. Choosing a standard one! (Top left cell's top let corner at <0,0>; cells are 1x1.)\n",
      "Warning! No geotransform defined. Choosing a standard one! (Top left cell's top let corner at <0,0>; cells are 1x1.)\n",
      "Warning! No geotransform defined. Choosing a standard one! (Top left cell's top let corner at <0,0>; cells are 1x1.)\n",
      "Warning! No geotransform defined. Choosing a standard one! (Top left cell's top let corner at <0,0>; cells are 1x1.)\n",
      "Warning! No geotransform defined. Choosing a standard one! (Top left cell's top let corner at <0,0>; cells are 1x1.)\n"
     ]
    }
   ],
   "source": [
    "datos['dem'] = rd.rdarray(datos['dem'], no_data=-9999)\n",
    "\n",
    "datos['slope'] = rd.TerrainAttribute(\n",
    "    rd.rdarray(datos['dem'], no_data=-9999),\n",
    "    attrib='slope_riserun'\n",
    ")\n",
    "datos['aspect'] = rd.TerrainAttribute(\n",
    "    rd.rdarray(datos['dem'], no_data=-9999), \n",
    "    attrib='aspect')\n",
    "\n",
    "datos['curvature'] = rd.TerrainAttribute(\n",
    "    rd.rdarray(datos['dem'], no_data=-9999), \n",
    "    attrib='profile_curvature'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_to_viz = 'aspect'\n",
    "\n",
    "plt.figure(figsize=(10,15))\n",
    "ax = plt.subplot(1,1,1)\n",
    "im = plt.imshow(\n",
    "    np.flipud(datos[feat_to_viz]),\n",
    "    origin='lower', \n",
    "    cmap='jet'\n",
    "#     vmin=0, vmax=360\n",
    ")\n",
    "# create an axes on the right side of ax. The width of cax will be 5%\n",
    "# of ax and the padding between cax and ax will be fixed at 0.05 inch.\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "\n",
    "plt.colorbar(im, cax=cax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stack all the Input Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['dem', 'vegh', 'slope', 'aspect', 'curvature']\n",
    "for f in features:\n",
    "    datos[f] = np.expand_dims(np.array(datos[f]), axis=-1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snowdepth (17002, 17569)\n",
      "vegh (17002, 17569, 1)\n",
      "dem (17002, 17569, 1)\n",
      "slope (17002, 17569, 1)\n",
      "aspect (17002, 17569, 1)\n",
      "curvature (17002, 17569, 1)\n"
     ]
    }
   ],
   "source": [
    "for llave, d in datos.items():\n",
    "    print(llave, d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.stack([d for llave, d in datos.items() if llave is not 'snowdepth'], axis=-1)\n",
    "Y = datos['snowdepth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../processed/datos.joblib']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(datos, '../../processed/datos.joblib')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xlist = ventana(signal=X, kernel_size=(1000, 1000), stride=(1000, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ylist = ventana(signal=Y, kernel_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:notebook] *",
   "language": "python",
   "name": "conda-env-notebook-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
